# -*- coding: utf-8 -*-
"""5.Random_forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_FZLBbaPrpkb9uTbwmTesMeeWMTbMDlT
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df= pd.read_csv('/content/winequality-red.csv')
df.head()

df.keys()

df.shape

df.describe()

df.info()

df.isnull().sum()

from sklearn.model_selection import train_test_split
X = df.drop(columns = 'quality')
y = df['quality']

X.head()

y.head()

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)
from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100)
clf.fit(X_train,y_train)

y_pred = clf.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print("Random Forest Accuracy on Wine dataset:", accuracy)

import pandas as pd
feature_imp = pd.Series(clf.feature_importances_, index=df.columns[:11]).sort_values(ascending=False)
feature_imp

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import seaborn as sns

sns.barplot(x=feature_imp, y=feature_imp.index, palette='hls')

plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Visualizing Important Features")
plt.legend()
plt.show()